version: "3.9"

services:
  # -------------------- Users --------------------
  users_redis:
    image: redis:7.0.11-alpine
    container_name: redis_users
    networks:
      - services_network
      - logging_network
    volumes:
      - redis_users_data:/data
    restart: always
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.users_redis"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  users_citus_coordinator:
    image: citusdata/citus:12
    platform: linux/amd64
    container_name: users_citus_coordinator
    restart: always
    env_file:
      - ./services/users/.env
    ports:
      - "5433:5432"
    networks:
      - services_network
      - logging_network
    volumes:
      - users_citus_coord_data:/var/lib/postgresql/data
      - ./services/users/init_db:/docker-entrypoint-initdb.d
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.users_citus_coordinator"
    depends_on:
      fluentd:
        condition: service_healthy

    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  users_citus_worker1:
    image: citusdata/citus:12
    platform: linux/amd64
    container_name: users_citus_worker1
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      # POSTGRES_HOST_AUTH_METHOD: trust
    networks:
      - services_network
      - logging_network
    volumes:
      - users_citus_worker1_data:/var/lib/postgresql/data
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.users_citus_worker1"
    depends_on:
      fluentd:
        condition: service_healthy

  users_citus_worker2:
    image: citusdata/citus:12
    platform: linux/amd64
    container_name: users_citus_worker2
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      # POSTGRES_HOST_AUTH_METHOD: trust
    networks:
      - services_network
      - logging_network
    volumes:
      - users_citus_worker2_data:/var/lib/postgresql/data
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.users_citus_worker2"
    depends_on:
      fluentd:
        condition: service_healthy

  users_service:
    build:
      context: ./services/users
      dockerfile: Dockerfile
    container_name: users_service
    command: sh -c "python manage.py migrate && gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 4"
    volumes:
      - ./services/users:/app
    env_file:
      - ./services/users/.env
    ports:
      - "8000"
    depends_on:
      users_redis:
        condition: service_healthy
      users_citus_coordinator:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - keycloak_keycloak_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.users_service"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/admin"]
      interval: 10s
      retries: 5

  # -------------------- Products --------------------
  products_redis:
    image: redis:7.0.11-alpine
    container_name: redis_products
    volumes:
      - redis_products_data:/data
    restart: always
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.products_redis"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  products_db:
    image: postgres
    container_name: db_products
    restart: always
    env_file:
      - ./services/products/.env
    volumes:
      - postgres_products_data:/var/lib/postgresql/data
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.products_db"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  products_service:
    build:
      context: ./services/products
      dockerfile: Dockerfile
    container_name: products_service
    command: sh -c "uvicorn main:app --host 0.0.0.0 --port 8001 --workers 4"
    volumes:
      - ./services/products/app:/app
    env_file:
      - ./services/products/.env
    ports:
      - "8001"
    depends_on:
      products_redis:
        condition: service_healthy
      products_db:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - keycloak_keycloak_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.products_service"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/docs"]
      interval: 10s
      retries: 5

  products_tracker:
    build:
      context: ./services/products
      dockerfile: Dockerfile
    container_name: products_tracker
    command: python -m events.products_tracker
    volumes:
      - ./services/products/app:/app
    env_file:
      - ./services/products/.env
    depends_on:
      products_service:
        condition: service_healthy
      kafka:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.products_tracker"
    restart: always

  # -------------------- Orders --------------------
  orders_mongodb:
    image: mongo
    container_name: orders_mongodb
    command: ["--replSet", "rs0", "--auth", "--keyFile", "/etc/mongo-keyfile/keyfile"]
    restart: always
    env_file:
      - ./services/orders/.env
    volumes:
      - ./services/orders/mongo_keyfile:/etc/mongo-keyfile
      - mongo_orders_data:/data/db
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.orders_mongodb"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 10s
      retries: 5

  orders_service:
    build:
      context: ./services/orders
      dockerfile: Dockerfile
    container_name: orders_service
    command: sh -c "uvicorn main:app --host 0.0.0.0 --port 8002 --workers 4"
    volumes:
      - ./services/orders/app:/app
    env_file:
      - ./services/orders/.env
    ports:
      - "8002"
    depends_on:
      orders_mongodb:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - keycloak_keycloak_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.orders_service"
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/docs"]
      interval: 10s
      retries: 5

  orders_tracker:
    build:
      context: ./services/orders
      dockerfile: Dockerfile
    container_name: orders_tracker
    command: python -m events.orders_tracker
    volumes:
      - ./services/orders/app:/app
    env_file:
      - ./services/orders/.env
    depends_on:
      orders_service:
        condition: service_healthy
      kafka:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.orders_tracker"
    restart: always

  # -------------------- Notifications --------------------
  notifications_redis:
    image: redis:7.0.11-alpine
    container_name: redis_notifications
    volumes:
      - redis_notifications_data:/data
    networks:
      - services_network
      - logging_network
    restart: always
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.notifications_redis"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5

  notifications_service:
    build:
      context: ./services/notifications
      dockerfile: Dockerfile
    container_name: notifications_service
    command: sh -c "celery -A celery_app worker -l info"
    volumes:
      - ./services/notifications/app:/app
    env_file:
      - ./services/notifications/.env
    depends_on:
      notifications_redis:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.notifications_service"
    restart: always

  notifications_consumer:
    build:
      context: ./services/notifications
      dockerfile: Dockerfile
    command: python -m consumer
    volumes:
      - ./services/notifications/app:/app
    env_file:
      - ./services/notifications/.env
    depends_on:
      notifications_service:
        condition: service_started
      kafka:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - logging_network
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.notifications_consumer"
    restart: always
    deploy:
      replicas: 3

  # -------------------- Gateway --------------------
  gateway:
    build:
      context: ./gateway
      dockerfile: Dockerfile
    container_name: gateway
    command: sh -c "uvicorn main:app --host 0.0.0.0 --port 8003 --workers 4"
    volumes:
      - ./gateway:/app
    env_file:
      - ./gateway/.env
    depends_on:
      users_service:
        condition: service_healthy
      products_service:
        condition: service_healthy
      orders_service:
        condition: service_healthy
      users_redis:
        condition: service_healthy
      fluentd:
        condition: service_healthy
    networks:
      - services_network
      - logging_network
    ports:
      - "8003:8003"
    restart: always
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.gateway"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health/"]
      interval: 10s
      retries: 5

  # -------------------- Kafka --------------------
  kafka:
    image: confluentinc/cp-kafka:7.8.3
    container_name: kafka
    ports:
      - "9092"
    networks:
      - services_network
      - logging_network
    environment:
      KAFKA_KRAFT_MODE: 'true'
      CLUSTER_ID: '1L6g7nGhU-eAKfL--X25wo'
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - kafka_kraft:/var/lib/kafka/data
    restart: always
    logging:
      driver: fluentd
      options:
        fluentd-address: "localhost:24224"
        tag: "docker.kafka"
    depends_on:
      fluentd:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092"]
      interval: 10s
      retries: 5

  # -------------------- Admin --------------------
  pgadmin:
    container_name: pgadmin
    image: dpage/pgadmin4
    networks:
      - services_network
    ports:
      - "5050:80"
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@example.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    restart: always

  mongo-express:
    image: mongo-express
    container_name: mongo_express
    restart: always
    ports:
      - "8081:8081"
    networks:
      - services_network
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://root:example@orders_mongodb:27017/
      ME_CONFIG_BASICAUTH_ENABLED: true
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: admin

  # -------------------- Logging --------------------
  fluentd:
    build:
      context: ./fluentd
      dockerfile: Dockerfile
    container_name: fluentd
    networks:
      - logging_network
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf
    depends_on:
        elasticsearch:
          condition: service_healthy
    healthcheck:
        test: ["CMD", "nc", "-z", "localhost", "24224"] 
        interval: 10s
        timeout: 5s
        retries: 5
        start_period: 30s

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.15.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.http.ssl.enabled=false
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
    networks:
      - logging_network
    ports:
      - "9200:9200"
    volumes:
      - elastic_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 40s

  kibana:
    image: docker.elastic.co/kibana/kibana:8.15.0
    container_name: kibana
    networks:
      - logging_network
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
        elasticsearch:
          condition: service_healthy
      
volumes:
  users_citus_coord_data:
  users_citus_worker1_data:
  users_citus_worker2_data:
  redis_users_data:

  postgres_products_data:
  redis_products_data:

  mongo_orders_data:

  redis_notifications_data:

  kafka_kraft:
  
  elastic_data:

networks:
  services_network:
    driver: bridge

  keycloak_keycloak_network:
    external: true

  logging_network:
    driver: bridge